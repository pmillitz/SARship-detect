{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591c7a77-9125-41c7-bb68-684148cfba6b",
   "metadata": {},
   "source": [
    "# CITS5014/15 Research Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a324d8b-a786-47c9-9b43-9868b2b43d5e",
   "metadata": {},
   "source": [
    "### Name: Peter Millitz [23088298]   Date: 17/10/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273164d-8926-4c3b-9fda-4248af807534",
   "metadata": {},
   "source": [
    "# Deep-Learning-Based Techniques for Ship Object Detection and Classification Using Complex-Valued SAR Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21db66-7d6b-4f10-8b1a-7f6c4e68c915",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d6821-34ae-4791-b25d-dfebf16da555",
   "metadata": {},
   "source": [
    "This research seeks to investigate the use of high-resolution complex-valued SLC data products from space-based SAR imagery for the tasks of ship detection, classification, and vessel regression using Deep Learning (DL). The basis for this investigation is the hypothesis that fully leveraging the information in the inherently complex-valued SAR imagery should naturally lead to superior model performance compared to real-valued networks. The underlying motivation is to achieve tangible improvements in the performance of existing SAR ship detection models used for maritime surveillance of IUU fishing activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1058df27-d20b-4ad0-b174-073ca6c63e34",
   "metadata": {},
   "source": [
    "## 2. The SARFish dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507d01d-fa5b-4bca-9b62-2f8df859d2fd",
   "metadata": {},
   "source": [
    "### 2.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b4df0-d541-480d-b060-a1af77176a71",
   "metadata": {},
   "source": [
    "SARFish is an imagery dataset for the purpose of training, validating and testing supervised machine learning models on the tasks of ship detection, classification and vessel length regression. SARFish builds on the work of the xView3-SAR dataset by expanding the imagery data to include Single Look Complex (SLC) as well as Ground Range Detected (GRD) imagery data taken directly from the European Space Agency (ESA) Copernicus Programme Open Access Hub Website.  \n",
    "\n",
    "The pre-processing applied to the Sentinel-1 images to the SARFish dataset was chosen to be deliberately minimal. The only operations applied to the SARFish data have been those necessary to make the images usable for computer vison tasks and include flipping, debursting and no-data masking. The philosophy was to provide GRD and SLC data in a format as close as practicable to the Sentinel-1 data that can be downloaded from Copernicus.  \n",
    "\n",
    "The three operations applied post download are describe below:  \n",
    "\n",
    "1. **Flipping:** Flipping was applied to both GRD and SLC products. Due to the acquisition methodology, raw images appear as mirror images of the surface of the Earth. This parity inversion between raw images and real-world coordinates is accounted for by reversing the image and its associated ground control points along the range or x-axis. \n",
    "\n",
    "2. **Debursting:** Debursting was applied only to SLC products. Sentinel-1 SLC products are provided as sets of 3 \"swaths\" per channel per scene. These swaths consist of \"sub-swaths\" or \"bursts\" which are overlapping segments of the image. The process of de-bursting is the alignment of these bursts into a contiguous image. This was done to create a one-to-one correspondence between the objects in each swath and the features on the Earth to which they correspond. It is important to note that as the deburst images are concatenations of bursts which themselves are individual SAR images, there are significant phase discontinuities on the boundaries of the bursts. It was decided for the purposes of this dataset that the bursts within the individual swaths should be merged rather than being split into separate images.\n",
    "\n",
    "3. **No data masking:** No data masking was applied to both GRD and SLC products. Invalid pixels in the image have been masked using a 'no data' mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa352c6-b0f9-4e82-a023-46e3c2796cb8",
   "metadata": {},
   "source": [
    "### 2.2. Dataset download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2758f-c999-47b3-a971-2854344fae85",
   "metadata": {},
   "source": [
    "All SLC (and corresponding GRD) products from the 50 scenes that comprise the 'validation' partition of the SARFish dataset, were downloaded for this project. The SARFish dataset resides in a Hugging Face repository available for download at: https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish. The validation partition was chosen because of the high prevalence of associated labelling where true vessel detections were of `HIGH` and `MEDIUM` confidence and bounding box coordinates were present. In contrast, the 'train' partition, although having many more scenes, entirely lacked labels with 'HIGH' confidence true vessel detections. Moreover, the majority of MEDIUM confidence labels did not have bounding boxes. The exact selection criteria for SLC images based on associated groundtruth labels is shown in Table 1 below.\n",
    "\n",
    "Table 1. Label criteria required for SLC image selection.\n",
    "\n",
    "|  Attribute |      Value(s)     |\n",
    "|:-----------|:------------------|\n",
    "|  is_vessel |        True       |\n",
    "| is_fishing |   True, False     |\n",
    "| confidence |   HIGH, MEDIUM    |\n",
    "|     top    |    not missing    |\n",
    "|     left   |    not missing    |\n",
    "|   bottom   |    not missing    |\n",
    "|    right   |    not missing    |\n",
    "\n",
    "A script, kindly supplied by one of the principal authors of the dataset^1, was customised to selectively download 50 SLC scenes selected from the validation partition (see script: *downloader/download_specific_files_from_the_SARFish_dataset_mod.py*). The script requires a specific python environment setup. The *requirements.txt* file used to create the python environment is included in the downloader directory.\n",
    "\n",
    "* Note: due to the debursting operation, each scene comprises three separate swaths (with small overlap), so the total number of images downloaded is actually 150.\n",
    "\n",
    "[1] Connor Luckett, connor.luckett@defence.cgov.au"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751dba96-7ee3-4874-b264-ce1dd3c38708",
   "metadata": {},
   "source": [
    "## 3. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc98972-7d51-42d2-a7fb-4fa10844bdfd",
   "metadata": {},
   "source": [
    "### 3.1 Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a748d-135b-4abe-a4b3-b971551f7f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import socket\n",
    "from time import time\n",
    "\n",
    "import numpy as np # np.__version__ = 1.26.4 (had to downgrade to version < 2.0)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # Added by PJM\n",
    "import yaml\n",
    "from GeoTiff import load_GeoTiff\n",
    "from complex_scale_and_norm import process_complex_data\n",
    "from utilities import *\n",
    "from batch_sar_processing import *\n",
    "from compare_crops import crop_compare\n",
    "from analyse_crop_stats import *\n",
    "\n",
    "%gui qt\n",
    "from visualise_labels import scale_sentinel_1_image, SARFish_Plot\n",
    "#from SARFish_metric import score\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6889e2-5201-4ceb-b4ca-82031bd1e152",
   "metadata": {},
   "source": [
    "### 3.2 Build root paths for raw and processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d4db6-10c7-4c23-9a3c-c1bc711fe2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the current hostname\n",
    "hostname = socket.gethostname()\n",
    "if \"kaya\" in hostname.lower() or os.getenv(\"HPC_ENV\") == \"true\":\n",
    "    system = \"kaya\"\n",
    "else:\n",
    "    system = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650a3e8-451d-4db0-a68b-70a0d84d6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml file\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Build the raw and processed data root paths\n",
    "sar_data_root = config[\"data_paths\"][\"SARFish_root_directory\"][system]\n",
    "gen_data_root = config[\"data_paths\"][\"Generated_root_directory\"][system]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09186470-ca65-4121-873f-5e5c9403ed60",
   "metadata": {},
   "source": [
    "### 3.3 Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8c687-7b4a-4275-854d-907af5eb4e69",
   "metadata": {},
   "source": [
    "First create a full list of qualifying validation partition scenes then partition it into train and test scene lists (90:10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db633d43-f221-4df2-92f6-6906c78a2b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of the 50 selected scene ids from the'validation' partition of the SARFish dataset downloaded from Hugging Face\n",
    "command = \"awk -F',' '{print $3}' ./SARFish_labels/validation/SLC/SLC_validation_labels.csv | tail -n +2 | sort -u\"\n",
    "fifty_scenes = extract_list_from_command(command, print_summary=True, columns=5, list_name=\"fifty_scenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce60c9f9-5965-45f7-acc3-e7ac9fe876b4",
   "metadata": {},
   "source": [
    "Ten percent of the 50 scenes will be randomly selected and set aside as the test set for later model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e650f-0e74-4716-9684-aeea83996d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly select 10% of scene_ids from the pool of 50 to be set aside as the test set. \n",
    "# Store the remainder as the train set to be used for training the model.\n",
    "train_scene_ids, test_scene_ids = train_test_split(fifty_scenes , test_ratio=0.1, seed=40)\n",
    "\n",
    "# Display the list of train_scene_ids and save to CSV file\n",
    "print(f\"Number of train scenes: {len(train_scene_ids)}\")\n",
    "print_list_formatted(train_scene_ids, 5, \"train_scene_ids\")\n",
    "save_list_to_txt(train_scene_ids, \"train_scene_ids.txt\")\n",
    "\n",
    "# Display the list of test_scene_ids and save to CSV file\n",
    "print(f\"Number of test scenes: {len(test_scene_ids)}\")\n",
    "print_list_formatted(test_scene_ids, 5 , \"test_scene_ids\")\n",
    "save_list_to_txt(test_scene_ids, \"test_scene_ids.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741f877-cbf7-470a-a24e-72d86b0fbf2d",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44915cb7-93d2-4974-af65-31a15002b8c6",
   "metadata": {},
   "source": [
    "### 4.1 Training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cb1dd-89bb-4f7a-bd2a-0212ee5b9aef",
   "metadata": {},
   "source": [
    "Load and examine the labels associated with each train scene_id. The labels are sourced from the master SLC 'validation' partition labels CSV file ('*SLC_validation_labels.csv*').\n",
    "\n",
    "Note: Only images with the appropriate level of labelling will be retained for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a185a-7598-4ee2-9bfe-41a8b558a51a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the the master SLC 'validation' partition labels CSV file in chunks, filtering on train dataset scene_ids.\n",
    "df_labels_train = pd.concat(\n",
    "    filter_rows(chunk, 'scene_id', train_scene_ids)\n",
    "    for chunk in pd.read_csv('./SARFish_labels/validation/SLC/SLC_validation_labels.csv', chunksize=5000)\n",
    ")\n",
    "# Display a few rows\n",
    "df_labels_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b040fcd-1d99-44b5-9592-558247587721",
   "metadata": {},
   "source": [
    "There are a total of 17,011 label entries across the 45 scenes in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cb7b8-e37c-481a-a1b9-fa3ba586cc00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates_val = df_labels_train[df_labels_train.duplicated(subset=['detect_id'], keep=False)]\n",
    "duplicates_val['detect_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4545ab-2a86-4149-85b4-14af3c2cd372",
   "metadata": {},
   "source": [
    "245 duplicate detection IDs were found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6ff23-f2b9-42a3-98cb-0a4deaab8170",
   "metadata": {},
   "source": [
    "Now filter the the dataframe for labels that meet the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4d2c9-b593-43ff-9474-54fa37a19332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter for true vessels detections which are either fishing or not and for which there is HIGH or MEDIUM confidence and\n",
    "# where the pixels locations of all four corners of the bounding box are not missing\n",
    "col_range = ['top', 'left', 'bottom', 'right'] # bounding box corner pixels\n",
    "\n",
    "df_labels_train_filt = df_labels_train[ ( (df_labels_train['is_vessel'] == True) & (df_labels_train['is_fishing'].notnull() ) &  \n",
    "                                    ( (df_labels_train['confidence'] == 'HIGH') | (df_labels_train['confidence'] == 'MEDIUM') ) & \n",
    "                                       df_labels_train[col_range].notnull().all(axis=1)) ]                                   \n",
    "# Display a few rows\n",
    "df_labels_train_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40657d0c-d431-48ef-b5d1-6864538de780",
   "metadata": {},
   "source": [
    "There are 3,603 labels in the train dataset that meet the selection criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3600c86-670e-4093-bd7a-22913c4521d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display an abbreviated column version of the previous dataframe\n",
    "df_labels_train_filt_abv = (df_labels_train_filt[['partition','product_type','scene_id','detect_id','swath_index',\n",
    "                                                  'detect_scene_column','detect_scene_row','top','left','bottom','right',\n",
    "                                                  'vessel_length_m','is_vessel','is_fishing','confidence']]\n",
    "                            .assign(detect_id=lambda x: '...' + x['detect_id'].str[-39:]))\n",
    "# Display a few rows\n",
    "df_labels_train_filt_abv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2a87c-aa94-4b50-9326-3b2f56c9e39c",
   "metadata": {},
   "source": [
    "The abbreviated display sample, above, shows the columns used for the selection cirteria: 'is_vessel' == True, 'is_fishing' is not missing and confidence has a valid value and all bounding box coordinates are populated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be50212-db7e-4420-851f-7a7d43cefc9f",
   "metadata": {},
   "source": [
    "Determine if any any swaths have missing labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93c32d-c056-4607-b731-f1a895e3ca9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, get the full set of expected swath indices\n",
    "expected_swaths = set([1, 2, 3])\n",
    "# Group by scene_id_ and collect the actual swath indices\n",
    "swaths_with_labels = df_labels_train_filt.groupby('scene_id')['swath_index'].apply(set).reset_index(name='swaths_with_labels')\n",
    "# Find the difference between expected and actual for each scene\n",
    "swaths_with_labels['swaths_missing_labels'] = swaths_with_labels['swaths_with_labels'].apply(lambda x: expected_swaths - x)\n",
    "# Filter down to scenes missing one or more swaths\n",
    "scenes_with_gaps = swaths_with_labels[swaths_with_labels['swaths_missing_labels'].apply(len) > 0]\n",
    "# Display scenes with one or more swaths with missing labels\n",
    "scenes_with_gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a557b09-2845-4f17-8b39-18ef0f4b6a5c",
   "metadata": {},
   "source": [
    "Ten scenes have at least one swath without labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8b7ef-3e74-4390-aeb1-efb7033c6c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine the number of unique scene_id/swath_index combinations present. \n",
    "# This will indicate the total number of images that meet the selection criteria.\n",
    "unique_combinations = df_labels_train_filt[['scene_id', 'swath_index']].drop_duplicates()\n",
    "count_images = len(unique_combinations)\n",
    "print(f\"Number of unique scene_id/swath_index entries: {count_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c8ee2-4aca-42ef-a703-3b83962af31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count and display the number of 'HIGH' and 'MEDIUM' confidence labels (including duplicates) in the train dataset\n",
    "labels_count = df_labels_train_filt['confidence'].value_counts()\n",
    "print(labels_count[['HIGH', 'MEDIUM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6303a3-286b-469b-a7b4-aad255c4f90b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count and display the number of non-fishing vessel and fishing vessel labels in the train dataset\n",
    "class_count = df_labels_train_filt[['is_fishing', 'is_vessel']].apply(pd.Series.value_counts)\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3593930-06ca-4815-8a6f-230f8e60eb7d",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "* There are a total of **17,011** label entries (rows) in total, encompassing 45 scenes. Of these, **245** have duplicated detection ids. This is attributed to the overlap between adjacent swaths i.e., a detection occurring in the overlap zone is recorded once, having a unique detection id, but is associated with both swaths and considered unique to each swath.\n",
    "* There are a total of **3,603** labels spread across the 45 scenes, which meet the selection criteria. The overwhelming majority are 'HIGH' confidence labels (3559) with only 44 'MEDIUM' confidence labels.\n",
    "* Of the 3,603 vessel detections, **901** (33.3%) are fishing vessels, indicating a class imbalance of almost exactly **3:1** in favour of non-fishing vessels.\n",
    "* There are **9** scenes identified that have one swath with no labels that meet the selection criteria plus **1** scene with two swaths with no labels that meet the selecton criteria. Since each swath is equivalent to one unique image product (i.e. '.tiff' file), this means 11 images in the dataset can't be used. This reduces the total number of images in the train dataset to **124**, down from the original 135.\n",
    "* The bounding box annotations use an **unconventional image origin** (bottom-left) for image coordinates systems. This needs to be accounted for to ensure compatibility downstream of the processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d813ec-58d4-4692-b324-cc96ad33ff5d",
   "metadata": {},
   "source": [
    "### 4.2 Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9764f4-2c4a-4e17-a690-b2859caa229c",
   "metadata": {},
   "source": [
    "#### 4.2.1 Statistical summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c50016-1152-412b-ade0-f2f415738c46",
   "metadata": {},
   "source": [
    "Compute summary statistics for each SLC VH-polarisation train scene image.\n",
    "\n",
    "(Original images are stored as GeoTIFF files and converted to numpy arrays. The arrays are saved to disk for later use.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44860593-5b25-48a3-93ff-9d792fc9d1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./compute_sar_stats.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa5c4c-893f-4f76-b986-9e43f83a22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build required paths\n",
    "input_path  = sar_data_root\n",
    "arrays_path = config[\"create_crop\"][\"arrays_path\"]\n",
    "output_path = os.path.join(gen_data_root, arrays_path)\n",
    "# Print the input and output paths created\n",
    "print(f\"input_path:  {input_path}\\noutput_path: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7d1fa-8dec-407d-b15f-471dabdd93f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute statistics for all train scene SLC VH-polarisation image (.tiff) files\n",
    "#%run compute_sar_stats.py {input_path} --pattern slc-vh --include-scene-ids train_scene_ids.txt --save-array {output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcc7f2-7597-49a3-905a-ca48403a23a8",
   "metadata": {},
   "source": [
    "Read the output file into a dataframe and display the full results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75eb13-f83f-4eba-9aea-73a9e1fa98b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the slc-vh stats tabulation  into a dataframe and display it\n",
    "df_slc_vh_stats = pd.read_csv('slc-vh_stats.csv')\n",
    "df_slc_vh_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef6601-d435-44ed-b7b1-38e5e9a93f01",
   "metadata": {},
   "source": [
    "Display an abbreviated version of the dataframe showing important columns only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca5921-8f6c-43fa-bcd8-341014a7e8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display abbreviated list of columns\n",
    "df_display = (df_slc_vh_stats[['scene_id', 'filename', 'valid_pixels', 'nan_count','zero_count', 'real_min', 'real_max',\n",
    "                               'amplitude_mean','amplitude_std','amplitude_min','amplitude_max','amplitude_median',\n",
    "                               'phase_circular_mean','phase_min', 'phase_max', 'phase_circular_std']]\n",
    "              .assign(filename=lambda x: x['filename'].str[:14] + '...'))\n",
    "df_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e2d05-01cd-4b99-872c-7518ff5e07dd",
   "metadata": {},
   "source": [
    "Determine the global minimum and maximum values of amplitude and phase across the 150 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2160f0-5bd7-43ab-9fdb-d06c67c650c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['amplitude_min','amplitude_max', 'real_min', 'real_max', 'phase_min', 'phase_max']\n",
    "column_maximums = df_display[cols].max()\n",
    "pd.set_option('display.precision', 10)\n",
    "print(column_maximums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aef2db-97b9-4f4f-8a28-86a16fcc3f4a",
   "metadata": {},
   "source": [
    "#### 4.2.2 Examine one image array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ddf0a-97f8-4214-be29-7ccb8513b5ef",
   "metadata": {},
   "source": [
    "Analyse one full-size image array from the dataset: `scene_id='5c3d986db930f848v'`, `swath_index=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74fe04-eaac-4685-94aa-00244089f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the image array filename to examine\n",
    "row = df_slc_vh_stats[(df_slc_vh_stats['scene_id']=='5c3d986db930f848v') & (df_slc_vh_stats['filename'].str.contains('002_SARFish', case=False, na=False))]\n",
    "npy_filename = re.sub(r'\\.\\w+$', '.npy', row['filename'].iloc[0])\n",
    "# Print the name of the image array file\n",
    "print(f\"Image array filename: {npy_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e2ea4-ec18-4c8d-b29f-89394e50ee40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the image array and print some vital stats\n",
    "slc_data = np.load(f\"{output_path}{npy_filename}\")\n",
    "print(f\"slc_data size:{slc_data.size}, slc_data.shape: {slc_data.shape}, slc_data dtype:{slc_data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0895855-00a7-4723-a40d-467bd89bcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispaly the computed statistics for that image array\n",
    "df_display.loc[[row.index[0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831893b0-7b4a-4925-bf3b-10be044e8e31",
   "metadata": {},
   "source": [
    "Plot histograms of the amplitude and phase diistribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f92148-3b10-480c-8380-01dfa565b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the raw amplitude and phase data   \n",
    "#vh_mag = np.abs(slc_data)\n",
    "#vh_phase = np.angle(slc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c8f0c-68bd-44c3-9947-0508c00f43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of raw amplitude and phase (randomly sampled)\n",
    "sample_size = 10000\n",
    "vh_mag_sample = np.random.choice(vh_mag.ravel(), sample_size, replace=False)\n",
    "vh_phase_sample = np.random.choice(vh_phase.ravel(), sample_size, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot histogram on the first subplot\n",
    "axes[0].hist(vh_mag_sample, bins=50, edgecolor='black')\n",
    "axes[0].set_title(\"(a) Amplitude\")\n",
    "axes[0].set_xlabel(\"Amplitude\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plot histogram on the second subplot\n",
    "axes[1].hist(vh_phase_sample, bins=50, edgecolor='black')\n",
    "axes[1].set_title(\"(b) Phase\")\n",
    "axes[1].set_xlabel(\"Phase (radians)\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Add super title\n",
    "fig.suptitle(\"Figure 1. Amplitude and Phase Frequency Distributions (sample size = 10000).\", fontsize=16)\n",
    "\n",
    "# Improve layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# free up memory\n",
    "vh_mag = None\n",
    "vh_phase = None\n",
    "slc_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe252a5-50ef-42f3-8a5a-c83d329c5aaf",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* The actual amplitude range for this image is [0.0, 2684.2] and the actual mean/median values are 19.3 and 15.0 respectively. The distribution is right skewed, starts at zero and has a long tail, resembling a Raleigh distribution, which is typical for this type of data (see Figure 1(a)).\n",
    "* Phase range is centred on zero radians with values in the range $(-\\pi, \\pi]$ and essentially distribution uniform across the range but with prominent high frequency peaks around $0$, $\\pm\\pi/2$ and $\\pi$ (see Figure 1(b)).\n",
    "* phase_max is effectively equal to $\\pi$ (discounting a small floating-point precision error) while the minimum phase is very close to $-\\pi$. These min/max values are characteristic across the 150 images.\n",
    "\n",
    "**Pre-processing recommendations: Scaling and Normalisation**\n",
    "* **Amplitude:** Logarithmic (decibel) transformation to compress dynamic range:\n",
    "  \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad vh\\_mag\\_db = 20\\log_{10}(vh\\_mag + \\epsilon)$,\n",
    "\n",
    "$\\quad~~$ where $\\epsilon$ is some small number (e.g. $10^-6$) to prevent log(0) errors, then normalise dB value to [0, 1] using min/max normalisation or percentile clipping to manage outliers.\n",
    "\n",
    "$\\quad~~$ Note: A factor of 20 is appropriate for decibel conversion of field measurements such has amplitude and maintains consistency with radar and SAR processing conventions.\n",
    "\n",
    "* **Phase:** The focus is on maintaining relative structure. Phase is inherently circular/periodic; representing phase as sine and cosine components respects the circular nature of phase and can be more suitable for training a neural network (eliminates the phase wraparound problem while keeping values in a well-behaved range). This representation only requires mapping the values to within the range expected for YOLO-compatibility ([-1, 1] -> [0,1]):\n",
    "\n",
    " $\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad phase\\_sin\\_norm = \\frac{(phase\\_sin + 1)}{2}\\quad\\text{and}$\n",
    " \n",
    " $\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad phase\\_cos\\_norm = \\frac{(phase\\_cos + 1)}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c3dfc-cf3c-4f50-8856-596f78627ced",
   "metadata": {},
   "source": [
    "#### 4.2.3 Displaying an SLC VH-polarisation image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4813496-2162-4816-b84a-53499d6ab7c7",
   "metadata": {},
   "source": [
    "Plot one swath of an SLC VH-polarisation scene from the validation partition, with 'HIGH' confidence labels.\n",
    "(The same image array in Section 4.1 is used here again).\n",
    "\n",
    "Note: The image is scaled, clipped, downsampled and the complex amplitude and phase data mapped into real intensity values for display purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa34d4d-0b59-4a13-9e97-f53c16cf6cbc",
   "metadata": {},
   "source": [
    "Build the image filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e2d65-acde-4c5c-97c8-b7c7f9ae3998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read correspondences file\n",
    "xView3_SLC_GRD_correspondences = pd.read_csv(\"xView3_SLC_GRD_correspondences.csv\") # in current working directory (\"SARFish/working/\")\n",
    "# Extract the validation partition row entry for scene_Id '5c3d986db930f848v' from the xView3_SLC_GRD_correspondences.csv file\n",
    "correspondence = xView3_SLC_GRD_correspondences[xView3_SLC_GRD_correspondences['scene_id'] == '5c3d986db930f848v'].squeeze()\n",
    "# Print extracted row entry details\n",
    "correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053b85d-dde3-43c6-9992-a119938a7e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the swath index for the selected scene\n",
    "swath_index = 2 # swath 2 of 3\n",
    "# Now build the path\n",
    "measurement_path_SLC = Path(sar_data_root, f\"{correspondence['SLC_product_identifier']}.SAFE\",\n",
    "                            \"measurement\", correspondence[f'SLC_swath_{swath_index}_vh'])\n",
    "# Check the path by printing it \n",
    "measurement_path_SLC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23cc89-0b8d-4263-8f70-693395d0a6b6",
   "metadata": {},
   "source": [
    "Load, prepare and plot the SLC image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44869d9f-6df4-4615-8061-cba4aa41e79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a scale factor to be used for downsampling the image for display\n",
    "scale_factor = 2 # retain every other pixel\n",
    "\n",
    "# Unpack image from GeoTIFF as a NumPy array\n",
    "data_SLC, nodata_mask_SLC, _, _ = load_GeoTiff(str(measurement_path_SLC))\n",
    "\n",
    "# Apply decibel scaling to image\n",
    "scaled_data_SLC = scale_sentinel_1_image(data_SLC, nodata_mask_SLC, product_type = \"SLC\")\n",
    "data_SLC = None # free up memory\n",
    "\n",
    "# Clip the scaled data\n",
    "clipped_scaled_data_SLC = np.clip(scaled_data_SLC, 15, 60)\n",
    "scaled_data_SLC = None # free up memory\n",
    "\n",
    "# Downsample the image\n",
    "clipped_scaled_data_SLC_resized = clipped_scaled_data_SLC[::scale_factor, ::scale_factor]\n",
    "clipped_scaled_data_SLC = None # free up memory\n",
    "\n",
    "# Downsample the nodata mask\n",
    "nodata_mask_SLC_resized = nodata_mask_SLC[::scale_factor, ::scale_factor]\n",
    "\n",
    "# Plot the final image\n",
    "plot_SLC = SARFish_Plot(clipped_scaled_data_SLC_resized, nodata_mask_SLC_resized,\n",
    "                        title = f\"SLC VH-polarisation product with labels, swath: {swath_index}\", show=True)\n",
    "\n",
    "# Clean up remaining intermediate products too free up memory\n",
    "nodata_mask_SLC_resized = None\n",
    "clipped_scaled_data_SLC_resized = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ad7b0-1b2e-4985-acfe-7866d16627f7",
   "metadata": {},
   "source": [
    "Load and display groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfce33-b0d6-44b8-b335-e8f88a5c14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_SLC = pd.read_csv('./SARFish_labels/validation/SLC/SLC_validation_labels.csv')\n",
    "groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['SLC_product_identifier'] == correspondence['SLC_product_identifier']]\n",
    "groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['confidence'] == 'HIGH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929e015-3de4-471d-81bc-a2fb6297aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale down the bounding box and target coordinates the match the image scale\n",
    "groundtruth_SLC[['detect_scene_column', 'detect_scene_row', 'left', 'right', 'bottom', 'top']] = \\\n",
    "groundtruth_SLC[['detect_scene_column', 'detect_scene_row', 'left', 'right', 'bottom', 'top']].apply(lambda x: round(x / scale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49607594-6a45-4fc1-950d-842de60069e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 'HIGH' confidence labels on the image currently displayed in the pop-up interactive window\n",
    "swath_groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['swath_index'] == swath_index]\n",
    "plot_SLC.add_bboxes(swath_groundtruth_SLC[['left', 'right', 'bottom', 'top']])\n",
    "plot_SLC.add_labels(columns = swath_groundtruth_SLC['detect_scene_column'], rows = swath_groundtruth_SLC['detect_scene_row'],\n",
    "                    categories = swath_groundtruth_SLC[['detect_id', 'is_vessel', 'is_fishing', 'vessel_length_m', 'confidence']],\n",
    "                    legend_label = \"groundtruth\", color = \"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3363e1-f30a-4a20-98c3-18a381744a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture and display the same image inline using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plot_SLC.render()  # Capture the VisPy canvas as an image\n",
    "plt.title(\"Figure 2. SLC VH-polarisation image with labels\")\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plot_SLC = None # free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86d4f8-c6a3-4aac-acbb-90c46882f01f",
   "metadata": {},
   "source": [
    "Figure 2 above, is the scaled, clipped and downsampled version of the SLC VH-polarisation product for scene_id '5c3d986db930f848v' (swath 2). The complex amplitude and phase data have been mapped into real intensity values for the display. Yellow boxes represent the bounding-boxes of the groundtruth labels, representing fishing vessels or non-fishing-vessels and where confidence = 'HIGH'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b458e-46ec-474e-a3c6-c684a1b6ea3f",
   "metadata": {},
   "source": [
    "## 5. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30a90b-dd54-46b5-bad3-cd16f98289e4",
   "metadata": {},
   "source": [
    "### 5.1 Create image crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df079c5-d1ba-4429-b3dd-ed3dba4e8180",
   "metadata": {},
   "source": [
    "Generate 96 x 96 pixel image crops from the raw image arrays saved to disk in Section 4.1. Each crop should be centred on a positive vessel detection location, with confidence level HIGH or MEDIUM, and have an associated bounding box.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Bounding box (BBox) annotations use inverse y-axis labeling i.e., image origin is bottom-left. This is corrected to top-left on-the-fly in the crop generating script `create_crop.py` below.\n",
    "* True positive vessel detections with BBoxes that extend beyond crop boundaries by more than 5 pixels are skipped. BBoxes extending by <= 5 pixels are shrunk to match the crop dimensions.\n",
    "* Crops where detections are close to the original image boundary are zero-padded to maintain a consistent crop-size. Crops with excessive padding (i.e., where padding encroaches on the BBox) are, as a rule, rejected. \n",
    "* The crop size of 96 x 96 pixels was chosen because it encapsulates most of the largest vessels in the dataset while minimising the background. Moreover, being a square crop-size of a multiple of 32, it is optimal for more efficient processing by models like YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5bef1-c27e-4bdc-8861-01ed8383db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training image crops - see config.yaml for configuration parameters, crops_log for full logging report.\n",
    "%run create_crop.py --config config.yaml --base-dir {gen_data_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf35e7a-278d-4738-8b6f-5d2b289f5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the processing summary from the crops_log\n",
    "!awk '/PROCESSING SUMMARY/ {found=1} found' ./crops_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc15a53-4e90-439a-949d-dddc91ab13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of of all 11 disqualified image arrays for reference\n",
    "command = \"awk -v pat='No crops created' '$0 ~ pat {print fname} {fname = $2}' ./crops_log\"\n",
    "disqualified_images = extract_list_from_command(command, output_file=\"disqualified_images.txt\", print_summary=True, columns=1, list_name=\"disqualified_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110c117-f7e5-422b-98c7-6cbf4447b36e",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "From Section 4.1, we saw there are a total of 3,603 positive vessel detection labels in the train dataset that fit the criteria defined in Section 2.2. The *crops_log* generated by the `create_crop.py` script reports that of the 135 input swaths (aka images) **3,577** image crops were created. **26** potential crops were skipped because the bounding boxes fell partially outside of the crop boundary by more than 5 pixels while **17** were retained by shrinking the edges of the bounding box by up to 5 pixels at either end. Another **5** crops required padding due to vessel detections very close to the image boundary. On visual inspection, **3** of the padded crops were rejected because the bounding boxes either straddled or lay very close to (within a few pixels) of the padded region. The log also reported that **11** input images failed label validation meaning no qualifying labels were present in the annotations file for these inputs. This was consistent with the observation in Section 4.1, i.e., for the 45 training scenes only 124 out of 135 images (aka swaths) had annotations with 'HIGH' or 'MEDIUM' confidence for positive vessel detections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6972608-fbe9-4ec3-affc-4bf9bc91281a",
   "metadata": {},
   "source": [
    "### 5.2 Crops analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0aa45e-0c48-4e21-8c6b-f5c7c70d03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse the magntiude and real components of crop pixels (all crops) to determine optimal visualisation parameters\n",
    "stats, mag_vals, log_vals, real_vals = analyse_crop_statistics('.') # base path to 'images' directory is current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b45039-6997-42ac-ad13-fd5a0127661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the formatted statistical summary with recommendations\n",
    "print_statistics_summary(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4ad69-357c-40f9-abb3-8ffdae0a41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution visualizations\n",
    "plot_distribution_analysis(stats, mag_vals, log_vals, real_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2359c6-7888-432e-85f7-9a1ad5e9f5d5",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "* Only the magnitude and real components, measured across all 3577 crops, are considered here, principally to determine optimal visualisation parameters.\n",
    "* The recommended normalisaton parameters determined above will be used for visualisations henceforth, where applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e13a8-e96a-4e48-b5b3-5fdc9aa9188e",
   "metadata": {},
   "source": [
    "### 5.3 Crop visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78cfff2-27a7-4c57-a25d-43ee36c4b533",
   "metadata": {},
   "source": [
    "#### 5.3.1 Interactive visual tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6eb30-d7b5-493d-9aed-ace4e09de2d4",
   "metadata": {},
   "source": [
    "An interactive tool to visualise the extracted crops was developed. The tool offers a selection of display modes, including magnitude (default) and decibel-scaled magnitude, phase, sin(phase), cos(phase), real and imaginary. The number of randomly selected image samples to view is user-selectable (default=50). It also offers a single-image view mode where the user nominates a specific image to view at launch. Optionally, bounding boxes can also displayed with the class of the detected object indicated ('is_fishing' or 'is_vessel')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080c190-4025-43b0-8af5-3bf7c277b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./visualise_crops.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c85925-542e-4824-a18e-4cf835f9f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch the interactive SAR image browser in raw magnitude (default) mode (swichable during the session)\n",
    "!./visualise_crops.py -i images -l labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44c782-0d93-4e4d-a253-a930cb8159a6",
   "metadata": {},
   "source": [
    "#### 5.3.2 Padded crop QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727147b2-93ee-48fa-aa56-f723d85e24bb",
   "metadata": {},
   "source": [
    "Visually examine the 5 padded crops created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dfcfe-0ecf-45a3-8a86-0a3fbb2f1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the images that have been padded\n",
    "command = \"awk -v pat='PADDED' '$0 ~ pat {print $2 \\\".npy\\\"}' ./crops_log\"\n",
    "padded_images = extract_list_from_command(command, output_file=\"padded_images.txt\", print_summary=True, columns=1, list_name=\"padded_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271326a2-b974-40c5-8e9a-4497aa6862a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each padded crops in both magnitude and log-magnitude display modes ('real' is an alternative display mode)\n",
    "crop_compare(padded_images, base_dir='.',\n",
    "             amp_min=0.0, amp_max=70.0,\n",
    "             log_min=0.0, log_max=36.9,\n",
    "             real_min=-35, real_max=35,\n",
    "             mode_row1='magnitude', mode_row2='log-magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4abd5-8974-4b36-a967-6f2dcf503c22",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "The plots above display the 5 padded crops in two separate display modes, raw magnitude and decibel-scaled magnitude.\n",
    "\n",
    "The first crop image shows a vessel positioned right up against the padded region border (original image boundary). The vessel signature is well defined, clearly oriented horizontally and consistent with its BBox placement. The faint vertical echoes extending into the padded region are typical of sidelobe artefacts commonly seen in SAR imagery.\n",
    "\n",
    "In the second crop, the BBox is poorly positioned over a vessel which appears to have a *vertical* rather than the horizontal orientation implied by the BBox. The vessel and BBox are also in very close proximity to the padded region border. It is unclear whether the faint echo emanating directly from the end of the vessel crossing into the padded region, is part of the vessel signature proper or not.\n",
    "\n",
    "The third crop image displays a highly questionable detection, with the 'vessel' pixels, positioned right on the border of the padded region, and having intensities virtually indistinguishable from the background.\n",
    "\n",
    "The last two images show two distinct vessel detections, including one of a very large vessel (**100.5 m** in length^2). Despite the close proximity of the larger vessel to the image border, this crop, and the last, are considered acceptable for use in training. The first crop is marginal however the second and third are considered unacceptable. \n",
    "\n",
    "[2] Vessel length data obtained from *SLC_validation_labels.csv* sourced from [xView3 website](https://iuu.xview.us/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b389b4-81fd-4b33-b93b-de67f30f7afb",
   "metadata": {},
   "source": [
    "### 5.4 Scaling and normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bec1c-31c0-4b83-832d-6bb46ea8d044",
   "metadata": {},
   "source": [
    "This section applies scaling and percentile clipping to amplitude data and sine and cosine transformations to phase data, in each training image crop. This is followed by normalisation to [0, 1] for YOLO compatiblity. The approach follows the recommendations in Section 4.2.1 and is informed by the statistical analysis of cropped images in Section 5.2. The final processing stage involves stacking the three components (amplitude_norm, phase_sin_norm and phase_cos_norm) in order to simulate the 3-channel RGB image input format expected by YOLO models (3, Height, Width).\n",
    "\n",
    "Note: With respect to amplitudes, it is assumed that non-fishing vessels display greater variability in amplitude intensity signatures relative to fishing vessels. This is because of their large variability in size, shape and construction. For example, large cargo/container ships generally show very high intensities resulting from corner reflections and metal structures, while smaller passenger ferries display more moderate intensities. Add to this the different orientations and aspect ratios, then a broad range of different backscatter levels could be expected. In contrast, fishing vessel backscatter levels would be expected to be mostly in the moderate range due to smaller size, different construction and materials used (wooden hulls as opposed to metal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451fb18-6882-4564-8cff-9f9822f6caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the core processing script command line parameters and usage examples for standalone use\n",
    "%run complex_scale_and_norm.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fd9e1-e5c5-4737-b6b2-04e9289623f9",
   "metadata": {},
   "source": [
    "Batch process the image crops created in Section 5.1 using the `batch_process_sar_data() function` which invokes the `complex_scale_and_norm.py` script. \n",
    "\n",
    "Use the 1st and 99th percentile of amplitude values (1.0 and 70.0 respectively) for the crops dataset computed in Section 5.2 to clip the amplitudes prior to scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aee48-6bb4-4d91-b6d3-c5a9abdbab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run batch_sar_processing.py --config config.yaml --base-dir {gen_data_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47334922-f5dc-4357-94c7-f1cfe4b84f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the processing summary from batch_sar_processing.log if needed\n",
    "#!head -n 5 ./batch_sar_processing.log; tail -n 6 ./batch_sar_processing.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a82aae-28f1-4d71-8922-ea78cc8beaf2",
   "metadata": {},
   "source": [
    "Load and display vital the stats for one scaled and normalised image crop array created in the previous cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d165f-de23-47ae-9515-3ae48644d61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build path to the processed crop images\n",
    "images_proc_path = Path(gen_data_root, config[\"batch_sar_processing\"][\"output_dir\"])\n",
    "# Check the path by printing it\n",
    "print(images_proc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01258f6-fcdb-4dc0-9ec0-ac73531c7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single normalised crop image\n",
    "slc_crop_norm = np.load(f\"{images_proc_path}/0d8ed29b0760dc59v_043.21094381000000339554_015.15049506000000079098_swath1_proc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8601298-6526-4a8a-ab0c-dcc7b80cd5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some vital statistics of the normalised crop image\n",
    "slc_crop_norm_vitals = {\n",
    "    \"size\": slc_crop_norm.size, \n",
    "    \"shape\": slc_crop_norm.shape, \n",
    "    \"dtype\": slc_crop_norm.dtype, \n",
    "    \"amp_min\": np.min(slc_crop_norm[:, :, 0]), \n",
    "    \"amp_max\": np.max(slc_crop_norm[:, :, 0]), \n",
    "    \"phase_sin_min\": np.min(slc_crop_norm[:, :, 1]), \n",
    "    \"phase_sin_max\": np.max(slc_crop_norm[:, :, 1]),\n",
    "    \"phase_cos_min\": np.min(slc_crop_norm[:, :, 2]), \n",
    "    \"phase_cos_max\": np.max(slc_crop_norm[:, :, 2])    \n",
    "}\n",
    "slc_crop_norm_vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b68ad-9934-4f59-ab41-0faa90bfa3a0",
   "metadata": {},
   "source": [
    "Shape of array and all channel ranges in expected range (YOLO-compatible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cc1e5-3f90-404b-a8fb-efc91b965e23",
   "metadata": {},
   "source": [
    "### 5.5 Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee3ad5-1a54-4d2d-a6cb-f1c8cc3f4bca",
   "metadata": {},
   "source": [
    "[Click here to visit YoTube on Mosaic Data Augmentation](https://www.youtube.com/watch?v=V6uj-eGmE7g&list=PLp5OuA3mFH5JTuKuk07wEMDylDF-Slo2W&index=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca6131-3af8-4e2a-b84f-217e7d568d54",
   "metadata": {},
   "source": [
    "## 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f89c0b-eed7-4461-b5c4-67796dfa6330",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fab9f0-659d-47be-8b28-f4c1c64e3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddf009-39b1-49fb-b65b-4e38e7d8c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1380e-ecbc-46c3-bf3c-6054fd732059",
   "metadata": {},
   "source": [
    "#### Verify installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132ec2b-cdea-4b54-a175-e2c945b2b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on an image\n",
    "results = model('https://ultralytics.com/images/bus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882fc44-9c31-40b2-b8be-c32d4e7e20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed results with bounding boxes and confidence\n",
    "for r in results:\n",
    "    print(f\"Detected {len(r.boxes)} objects\")\n",
    "    \n",
    "    # Access bounding box information\n",
    "    if r.boxes is not None:\n",
    "        boxes = r.boxes.xyxy  # bounding boxes in xyxy format\n",
    "        confidences = r.boxes.conf  # confidence scores\n",
    "        classes = r.boxes.cls  # class indices\n",
    "        \n",
    "        print(\"\\nDetailed detections:\")\n",
    "        for i, (box, conf, cls_idx) in enumerate(zip(boxes, confidences, classes)):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            class_name = r.names[int(cls_idx)]\n",
    "            \n",
    "            print(f\"Object {i+1}:\")\n",
    "            print(f\"  Class: {class_name} (ID: {int(cls_idx)})\")\n",
    "            print(f\"  Confidence: {conf:.4f}\")\n",
    "            print(f\"  Bounding box: ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})\")\n",
    "            print(f\"  Box format: (x1, y1, x2, y2)\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc9753-b5c8-4567-bcc0-fdea82d25331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results with bounding boxes drawn\n",
    "results[0].save('output_with_boxes.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854ab83-6762-4766-a403-a454539b63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the underlying PyTorch model\n",
    "pytorch_model = model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238bbd3-156a-4288-b056-c0e2cb8274fc",
   "metadata": {},
   "source": [
    "#### Examine the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1083c4a-97fe-4c82-b333-f460db9b8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the model architecture\n",
    "print(pytorch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48508c4-33e3-4d83-87b1-80f0fd556b7b",
   "metadata": {},
   "source": [
    "UNDER CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca764e-c3c1-4d0d-a541-bbc45df70fc8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, PowerNorm\n",
    "import gc\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "def analyze_vessel_crop(complex_crop, crop_id=None, center_radius=10):\n",
    "    \"\"\"\n",
    "    Analyze a single 64x64 vessel crop to extract vessel and background characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    complex_crop : numpy.ndarray\n",
    "        64x64 complex-valued SAR crop with vessel at center\n",
    "    crop_id : str, optional\n",
    "        Identifier for this crop\n",
    "    center_radius : int\n",
    "        Radius around center to consider as vessel region\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Analysis results including vessel/background statistics\n",
    "    \"\"\"\n",
    "    h, w = complex_crop.shape\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    \n",
    "    # Create masks for vessel (center) and background regions\n",
    "    y_coords, x_coords = np.ogrid[:h, :w]\n",
    "    vessel_mask = ((x_coords - center_x)**2 + (y_coords - center_y)**2) <= center_radius**2\n",
    "    background_mask = ~vessel_mask\n",
    "    \n",
    "    # Extract amplitude and phase\n",
    "    amplitude = np.abs(complex_crop)\n",
    "    phase = np.angle(complex_crop)\n",
    "    \n",
    "    # Vessel statistics\n",
    "    vessel_amp = amplitude[vessel_mask]\n",
    "    vessel_phase = phase[vessel_mask]\n",
    "    \n",
    "    # Background statistics  \n",
    "    bg_amp = amplitude[background_mask]\n",
    "    bg_phase = phase[background_mask]\n",
    "    \n",
    "    # Remove invalid values\n",
    "    vessel_amp = vessel_amp[np.isfinite(vessel_amp) & (vessel_amp > 0)]\n",
    "    vessel_phase = vessel_phase[np.isfinite(vessel_phase)]\n",
    "    bg_amp = bg_amp[np.isfinite(bg_amp) & (bg_amp > 0)]\n",
    "    bg_phase = bg_phase[np.isfinite(bg_phase)]\n",
    "    \n",
    "    return {\n",
    "        'crop_id': crop_id,\n",
    "        'vessel_amp_mean': np.mean(vessel_amp) if len(vessel_amp) > 0 else 0,\n",
    "        'vessel_amp_std': np.std(vessel_amp) if len(vessel_amp) > 0 else 0,\n",
    "        'vessel_amp_max': np.max(vessel_amp) if len(vessel_amp) > 0 else 0,\n",
    "        'bg_amp_mean': np.mean(bg_amp) if len(bg_amp) > 0 else 0,\n",
    "        'bg_amp_std': np.std(bg_amp) if len(bg_amp) > 0 else 0,\n",
    "        'contrast_ratio': (np.mean(vessel_amp) / np.mean(bg_amp)) if len(bg_amp) > 0 and np.mean(bg_amp) > 0 else 0,\n",
    "        'vessel_pixels': len(vessel_amp),\n",
    "        'bg_pixels': len(bg_amp),\n",
    "        'vessel_phase_var': np.var(vessel_phase) if len(vessel_phase) > 0 else 0,\n",
    "        'bg_phase_var': np.var(bg_phase) if len(bg_phase) > 0 else 0\n",
    "    }\n",
    "\n",
    "def create_crop_histogram(complex_crops, crop_ids=None, n_bins_phase=64, n_bins_amp=32,\n",
    "                         analysis_type='vessel_focused', center_radius=10):\n",
    "    \"\"\"\n",
    "    Create phase-amplitude histogram for vessel crops.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    complex_crops : list or numpy.ndarray\n",
    "        List of 64x64 complex crops, or single 3D array (N, 64, 64)\n",
    "    crop_ids : list, optional\n",
    "        Identifiers for each crop\n",
    "    n_bins_phase : int\n",
    "        Number of phase bins\n",
    "    n_bins_amp : int  \n",
    "        Number of amplitude bins\n",
    "    analysis_type : str\n",
    "        'vessel_focused' - Focus on vessel regions only\n",
    "        'full_crop' - Analyze entire crop\n",
    "        'comparative' - Compare vessel vs background\n",
    "    center_radius : int\n",
    "        Radius for vessel region definition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle input format\n",
    "    if isinstance(complex_crops, np.ndarray):\n",
    "        if complex_crops.ndim == 2:\n",
    "            complex_crops = [complex_crops]\n",
    "        elif complex_crops.ndim == 3:\n",
    "            complex_crops = [complex_crops[i] for i in range(complex_crops.shape[0])]\n",
    "    \n",
    "    n_crops = len(complex_crops)\n",
    "    if crop_ids is None:\n",
    "        crop_ids = [f\"Crop_{i:03d}\" for i in range(n_crops)]\n",
    "    \n",
    "    print(f\"Processing {n_crops} vessel crops...\")\n",
    "    \n",
    "    # Collect statistics for all crops\n",
    "    crop_stats = []\n",
    "    all_vessel_amp = []\n",
    "    all_vessel_phase = []\n",
    "    all_bg_amp = []\n",
    "    all_bg_phase = []\n",
    "    \n",
    "    for i, crop in enumerate(complex_crops):\n",
    "        if crop.shape != (64, 64):\n",
    "            print(f\"Warning: Crop {i} has shape {crop.shape}, expected (64, 64)\")\n",
    "            continue\n",
    "            \n",
    "        stats = analyze_vessel_crop(crop, crop_ids[i], center_radius)\n",
    "        crop_stats.append(stats)\n",
    "        \n",
    "        # Extract vessel and background data\n",
    "        h, w = crop.shape\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        y_coords, x_coords = np.ogrid[:h, :w]\n",
    "        vessel_mask = ((x_coords - center_x)**2 + (y_coords - center_y)**2) <= center_radius**2\n",
    "        \n",
    "        amplitude = np.abs(crop)\n",
    "        phase = np.angle(crop)\n",
    "        \n",
    "        if analysis_type == 'vessel_focused':\n",
    "            vessel_amp_crop = amplitude[vessel_mask]\n",
    "            vessel_phase_crop = phase[vessel_mask]\n",
    "            valid_mask = np.isfinite(vessel_amp_crop) & (vessel_amp_crop > 0) & np.isfinite(vessel_phase_crop)\n",
    "            all_vessel_amp.extend(vessel_amp_crop[valid_mask])\n",
    "            all_vessel_phase.extend(vessel_phase_crop[valid_mask])\n",
    "            \n",
    "        elif analysis_type == 'full_crop':\n",
    "            amp_flat = amplitude.ravel()\n",
    "            phase_flat = phase.ravel()\n",
    "            valid_mask = np.isfinite(amp_flat) & (amp_flat > 0) & np.isfinite(phase_flat)\n",
    "            all_vessel_amp.extend(amp_flat[valid_mask])\n",
    "            all_vessel_phase.extend(phase_flat[valid_mask])\n",
    "            \n",
    "        else:  # comparative\n",
    "            # Vessel region\n",
    "            vessel_amp_crop = amplitude[vessel_mask]\n",
    "            vessel_phase_crop = phase[vessel_mask]\n",
    "            valid_vessel = np.isfinite(vessel_amp_crop) & (vessel_amp_crop > 0) & np.isfinite(vessel_phase_crop)\n",
    "            all_vessel_amp.extend(vessel_amp_crop[valid_vessel])\n",
    "            all_vessel_phase.extend(vessel_phase_crop[valid_vessel])\n",
    "            \n",
    "            # Background region  \n",
    "            bg_amp_crop = amplitude[~vessel_mask]\n",
    "            bg_phase_crop = phase[~vessel_mask]\n",
    "            valid_bg = np.isfinite(bg_amp_crop) & (bg_amp_crop > 0) & np.isfinite(bg_phase_crop)\n",
    "            all_bg_amp.extend(bg_amp_crop[valid_bg])\n",
    "            all_bg_phase.extend(bg_phase_crop[valid_bg])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_vessel_amp = np.array(all_vessel_amp)\n",
    "    all_vessel_phase = np.array(all_vessel_phase)\n",
    "    \n",
    "    if len(all_vessel_amp) == 0:\n",
    "        print(\"Error: No valid vessel pixels found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"Collected {len(all_vessel_amp):,} vessel pixels from {n_crops} crops\")\n",
    "    if analysis_type == 'comparative':\n",
    "        print(f\"Collected {len(all_bg_amp):,} background pixels\")\n",
    "        print(f\"Vessel amplitude range: {np.min(all_vessel_amp):.4f} - {np.max(all_vessel_amp):.4f}\")\n",
    "        if len(all_bg_amp) > 0:\n",
    "            print(f\"Background amplitude range: {np.min(all_bg_amp):.4f} - {np.max(all_bg_amp):.4f}\")\n",
    "    \n",
    "    # Phase bins\n",
    "    phase_edges = np.linspace(-np.pi, np.pi, n_bins_phase + 1)\n",
    "    \n",
    "    # Create histograms\n",
    "    if analysis_type == 'comparative' and len(all_bg_amp) > 0:\n",
    "        all_bg_amp = np.array(all_bg_amp)\n",
    "        all_bg_phase = np.array(all_bg_phase)\n",
    "        \n",
    "        # For comparative analysis, create amplitude bins that cover both vessel and background\n",
    "        combined_amp = np.concatenate([all_vessel_amp, all_bg_amp])\n",
    "        amp_min = np.percentile(combined_amp, 1)\n",
    "        amp_max = np.percentile(combined_amp, 99.5)\n",
    "        \n",
    "        # Ensure minimum value is positive for log scale\n",
    "        amp_min = max(amp_min, 1e-6)\n",
    "        amp_max = max(amp_max, amp_min * 10)  # Ensure meaningful range\n",
    "        \n",
    "        print(f\"Combined amplitude range for binning: {amp_min:.6f} - {amp_max:.6f}\")\n",
    "        \n",
    "        try:\n",
    "            amp_edges = np.logspace(np.log10(amp_min), np.log10(amp_max), n_bins_amp + 1)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error creating log bins: {e}\")\n",
    "            print(\"Falling back to linear binning\")\n",
    "            amp_edges = np.linspace(amp_min, amp_max, n_bins_amp + 1)\n",
    "        \n",
    "        # Create separate histograms for vessel and background\n",
    "        hist_vessel, _, _ = np.histogram2d(all_vessel_phase, all_vessel_amp, \n",
    "                                         bins=[phase_edges, amp_edges])\n",
    "        hist_bg, _, _ = np.histogram2d(all_bg_phase, all_bg_amp,\n",
    "                                     bins=[phase_edges, amp_edges])\n",
    "    else:\n",
    "        # Create amplitude bins - adaptive to vessel data range only\n",
    "        amp_min = np.percentile(all_vessel_amp, 1)\n",
    "        amp_max = np.percentile(all_vessel_amp, 99.5)\n",
    "        \n",
    "        # Ensure minimum value is positive for log scale\n",
    "        amp_min = max(amp_min, 1e-6)\n",
    "        amp_max = max(amp_max, amp_min * 10)  # Ensure meaningful range\n",
    "        \n",
    "        try:\n",
    "            amp_edges = np.logspace(np.log10(amp_min), np.log10(amp_max), n_bins_amp + 1)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error creating log bins: {e}\")\n",
    "            print(\"Falling back to linear binning\")\n",
    "            amp_edges = np.linspace(amp_min, amp_max, n_bins_amp + 1)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Vessel histogram\n",
    "        im1 = ax1.imshow(hist_vessel.T + 1, extent=[-np.pi, np.pi, 0, n_bins_amp],\n",
    "                        origin='lower', aspect='auto', cmap='hot', norm=LogNorm())\n",
    "        ax1.set_title(f'Vessel Regions (n={n_crops} crops)')\n",
    "        ax1.set_xlabel('Phase (radians)')\n",
    "        ax1.set_ylabel('Amplitude Bin')\n",
    "        plt.colorbar(im1, ax=ax1, label='Frequency')\n",
    "        \n",
    "        # Background histogram\n",
    "        im2 = ax2.imshow(hist_bg.T + 1, extent=[-np.pi, np.pi, 0, n_bins_amp],\n",
    "                        origin='lower', aspect='auto', cmap='blues', norm=LogNorm())\n",
    "        ax2.set_title('Background Regions')\n",
    "        ax2.set_xlabel('Phase (radians)')\n",
    "        ax2.set_ylabel('Amplitude Bin')\n",
    "        plt.colorbar(im2, ax=ax2, label='Frequency')\n",
    "        \n",
    "        # Phase comparison\n",
    "        phase_centers = (phase_edges[:-1] + phase_edges[1:]) / 2\n",
    "        vessel_phase_dist = np.sum(hist_vessel, axis=1)\n",
    "        bg_phase_dist = np.sum(hist_bg, axis=1)\n",
    "        \n",
    "        ax3.plot(phase_centers, vessel_phase_dist, 'r-', label='Vessel', linewidth=2)\n",
    "        ax3.plot(phase_centers, bg_phase_dist, 'b-', label='Background', linewidth=2)\n",
    "        ax3.set_xlabel('Phase (radians)')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.set_title('Phase Distribution Comparison')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Amplitude comparison\n",
    "        amp_centers = np.sqrt(amp_edges[:-1] * amp_edges[1:])\n",
    "        vessel_amp_dist = np.sum(hist_vessel, axis=0)\n",
    "        bg_amp_dist = np.sum(hist_bg, axis=0)\n",
    "        \n",
    "        ax4.loglog(amp_centers, vessel_amp_dist + 1, 'r-', label='Vessel', linewidth=2)\n",
    "        ax4.loglog(amp_centers, bg_amp_dist + 1, 'b-', label='Background', linewidth=2)\n",
    "        ax4.set_xlabel('Amplitude')\n",
    "        ax4.set_ylabel('Frequency')\n",
    "        ax4.set_title('Amplitude Distribution Comparison')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        main_hist = hist_vessel\n",
    "        \n",
    "    else:\n",
    "        # Single histogram\n",
    "        hist_2d, _, _ = np.histogram2d(all_vessel_phase, all_vessel_amp,\n",
    "                                     bins=[phase_edges, amp_edges])\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Main histogram\n",
    "        im1 = ax1.imshow(hist_2d.T + 1, extent=[-np.pi, np.pi, 0, n_bins_amp],\n",
    "                        origin='lower', aspect='auto', cmap='plasma', norm=PowerNorm(gamma=0.5))\n",
    "        title = f'Vessel Crops Phase-Amplitude ({analysis_type})'\n",
    "        ax1.set_title(title)\n",
    "        ax1.set_xlabel('Phase (radians)')\n",
    "        ax1.set_ylabel('Amplitude Bin')\n",
    "        plt.colorbar(im1, ax=ax1, label='Frequency')\n",
    "        \n",
    "        # Phase distribution\n",
    "        phase_centers = (phase_edges[:-1] + phase_edges[1:]) / 2\n",
    "        phase_dist = np.sum(hist_2d, axis=1)\n",
    "        ax2.plot(phase_centers, phase_dist, 'g-', linewidth=2)\n",
    "        ax2.set_xlabel('Phase (radians)')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Phase Distribution')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Amplitude distribution\n",
    "        amp_centers = np.sqrt(amp_edges[:-1] * amp_edges[1:])\n",
    "        amp_dist = np.sum(hist_2d, axis=0)\n",
    "        ax3.loglog(amp_centers, amp_dist + 1, 'purple', linewidth=2)\n",
    "        ax3.set_xlabel('Amplitude')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.set_title('Amplitude Distribution')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Crop statistics summary\n",
    "        if crop_stats:\n",
    "            contrast_ratios = [s['contrast_ratio'] for s in crop_stats if s['contrast_ratio'] > 0]\n",
    "            vessel_amps = [s['vessel_amp_mean'] for s in crop_stats if s['vessel_amp_mean'] > 0]\n",
    "            \n",
    "            ax4.hist(contrast_ratios, bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "            ax4.set_xlabel('Vessel/Background Contrast Ratio')\n",
    "            ax4.set_ylabel('Number of Crops')\n",
    "            ax4.set_title(f'Contrast Distribution (n={len(contrast_ratios)})')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        main_hist = hist_2d\n",
    "    \n",
    "    # Format phase ticks\n",
    "    phase_ticks = [-np.pi, -np.pi/2, 0, np.pi/2, np.pi]\n",
    "    phase_labels = ['-π', '-π/2', '0', 'π/2', 'π']\n",
    "    for ax in fig.get_axes():\n",
    "        if 'Phase' in ax.get_xlabel():\n",
    "            ax.set_xticks(phase_ticks)\n",
    "            ax.set_xticklabels(phase_labels)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Summary statistics\n",
    "    summary = {\n",
    "        'n_crops': n_crops,\n",
    "        'total_pixels': len(all_vessel_amp),\n",
    "        'amp_range': (np.min(all_vessel_amp), np.max(all_vessel_amp)),\n",
    "        'mean_contrast': np.mean([s['contrast_ratio'] for s in crop_stats if s['contrast_ratio'] > 0]),\n",
    "        'crop_stats': crop_stats\n",
    "    }\n",
    "    \n",
    "    return fig, main_hist, summary\n",
    "\n",
    "def batch_process_crops(crop_directory=None, complex_crops=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Batch process multiple vessel crops.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    crop_directory : str, optional\n",
    "        Directory containing .npy files of crops\n",
    "    complex_crops : list/array, optional  \n",
    "        Direct array of crops\n",
    "    **kwargs : additional arguments for create_crop_histogram\n",
    "    \"\"\"\n",
    "    \n",
    "    if crop_directory is not None:\n",
    "        import os\n",
    "        crop_files = [f for f in os.listdir(crop_directory) if f.endswith('.npy')]\n",
    "        crop_ids = [f.replace('.npy', '') for f in crop_files]\n",
    "        complex_crops = [np.load(os.path.join(crop_directory, f)) for f in crop_files]\n",
    "        print(f\"Loaded {len(complex_crops)} crops from {crop_directory}\")\n",
    "    \n",
    "    elif complex_crops is None:\n",
    "        print(\"Error: Must provide either crop_directory or complex_crops\")\n",
    "        return None\n",
    "        \n",
    "    return create_crop_histogram(complex_crops, crop_ids, **kwargs)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Create synthetic vessel crops for testing\n",
    "    print(\"Creating example vessel crops...\")\n",
    "    \n",
    "    # Generate synthetic 64x64 crops with vessels at center\n",
    "    n_test_crops = 5\n",
    "    test_crops = []\n",
    "    \n",
    "    for i in range(n_test_crops):\n",
    "        # Create background sea clutter\n",
    "        crop = (np.random.randn(64, 64) + 1j * np.random.randn(64, 64)) * 0.5\n",
    "        \n",
    "        # Add vessel signature at center\n",
    "        center_x, center_y = 32, 32\n",
    "        vessel_size = np.random.randint(6, 12)\n",
    "        vessel_amp = np.random.uniform(3, 8)\n",
    "        \n",
    "        y_coords, x_coords = np.ogrid[:64, :64]\n",
    "        vessel_mask = ((x_coords - center_x)**2 + (y_coords - center_y)**2) <= vessel_size**2\n",
    "        \n",
    "        # Add vessel with higher amplitude and specific phase pattern\n",
    "        vessel_phase = np.random.uniform(-np.pi, np.pi)\n",
    "        crop[vessel_mask] = vessel_amp * np.exp(1j * vessel_phase)\n",
    "        \n",
    "        test_crops.append(crop)\n",
    "    \n",
    "    # Test different analysis types\n",
    "    analysis_types = ['vessel_focused', 'full_crop', 'comparative']\n",
    "    \n",
    "    for analysis in analysis_types:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Analysis type: {analysis}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        fig, hist, summary = create_crop_histogram(\n",
    "            test_crops,\n",
    "            analysis_type=analysis,\n",
    "            n_bins_phase=32,\n",
    "            n_bins_amp=24,\n",
    "            center_radius=8\n",
    "        )\n",
    "        \n",
    "        if summary:\n",
    "            print(f\"Processed {summary['n_crops']} crops\")\n",
    "            print(f\"Total pixels analyzed: {summary['total_pixels']:,}\")\n",
    "            print(f\"Amplitude range: {summary['amp_range'][0]:.2f} - {summary['amp_range'][1]:.2f}\")\n",
    "            print(f\"Mean contrast ratio: {summary['mean_contrast']:.2f}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        cont = input(\"Continue to next analysis? (y/n): \")\n",
    "        if not cont.lower().startswith('y'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7df0f-fb18-4ba2-bd84-a57305c68c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a73d08-405a-40e0-b38d-bf3308114c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d67799-3d65-4aef-8593-4fdc3195d1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
